# [WIP] wikiscrap

## Introduction

En cliquant continuellement sur le premier lien d'une suite d'articles Wikipédia, on fini toujours par tomber sur la même page...
Essayez vous-même : [Wikipédia - Article au hasard](https://fr.wikipedia.org/wiki/Sp%C3%A9cial:Page_au_hasard).

## Hypothèse

De prime abord, une explication à ce processus semble être toute trouvée.

En effet, les articles sont rédigés sensiblement tous de la manière malgré la grande diversité des rédacteurs d'articles Wikipédia. Ainsi, le premier lien cliquable paraît quasiment systématiquement faire appel à une notion très proche de l'article en question.

Exemple :

    Document > Signe > Marque > Dictionnaires Le Robert > Maison d'édition > Entreprise > Organisation > Sciences humaines et sociales > Discipline (spécialité) > Savoir > Connaissance > Notion > Connaissance (philosophie) > Philosophie > Grec ancien > Grec > Grec moderne > Langue > Système > Ensemble > Mathématiques > Connaissance > Notion > etc... (boucle)

On peut cependant repérer quelques contres exemples : le premier lien cliquable sur l'article d'un écrivain peut être un lien vers son jour de naissance. Ces écarts à l'hypothétique règle entraînent une erreur de parcours, mais les pages suivantes corrigent le tir et ramènent toujours à une notion plus proche.

Le fait que la page sur la connaissance soit à l'origine d'une boucle semble être simplement lié au fait que les sujets de cette boucle se font itérativement référence entre eux.

Cependant, comment expliquer que tous les sujets semblent finir par tomber dans cette boucle ? Existe-t-il des articles non concernés par ce fait ? Existe-t-il d'autres boucles ? Que peut-on dire sur l'article qui semble être le point commun de tous les sujets de Wikipédia ?

## Objectifs

Pour tenter de trouver des réponses, ce programme a pour principal objectif de recenser et visualiser un vaste ensemble de chemins réalisés par ce processus, le point de départ - la première page Wikipédia - étant tiré au hasard.

En changeant quelques paramètres (position du mot cliqué, langue des pages, ...), il pourra être possible de changer le contexte et de constater si ce phénomène est spécifique à une configuration ou peut apporter des réponses en fonction des différents résultats observés.

## Configuration de base

Le programme principal, un crawler, se charge de récupérer tous les liens contenus dans la zone principale d'un article Wikipédia donné (génère un article au hasard si aucun lien ne lui est donné).

Pour une meilleure expérience, les liens redirigeant vers une date (date de naissance d'un auteur, par exemple) et vers l'alphabet phonétique internationnal ne sont pas retournés par le crawler.

## Liens utiles

[Web scraping](https://fr.wikipedia.org/wiki/Web_scraping).
